// Copyright 2024 Dimitrios Papakonstantinou. All rights reserved.
// Use of this source code is governed by a MIT
// license that can be found in the LICENSE file.

use crate::lexer::TokenType;

#[derive(Eq, PartialEq, Debug, Clone)]
pub enum Item {
    Program,
    FunctionDefinition,
    Function(String),
    Statement,
    Expression,
    Constant(isize),
}

#[derive(Debug, Clone)]
pub struct ParseNode {
    children: Vec<ParseNode>,
    entry: Item,
}

// Parse the token vector and creates the AST
pub struct Parser<'p> {
    tokens: &'p Vec<TokenType>, // Tokens generated by lexer
    current: usize,             // Current index in Token Vector
}

impl<'p> Parser<'p> {
    // Initialise Parser struct
    pub fn new(tokens: &'p Vec<TokenType>) -> Self {
        Self { tokens, current: 0 }
    }

    fn parse_statement(&mut self) -> ParseNode {
        self.expect(TokenType::ReturnKeyword);
        let return_val = self.parse_exp(); //TODO
        self.expect(TokenType::Semicolon);

        return return_val;
    }

    fn parse_exp(&mut self) -> ParseNode {}

    // Check if the current token is corrent with the languages grammer
    fn expect(&mut self, expected: TokenType) -> () {
        //TODO consider using pop instead of get
        let actual = self.tokens.get(self.current).unwrap_or_else(|| {
            panic!("Failed to retrieve Token");
        });

        if *actual != expected {
            panic!(
                "Syntax error. Expected Token: {}. Actual Token: {}",
                expected, *actual
            );
        } else {
            self.current += 1;
        }
    }
}
